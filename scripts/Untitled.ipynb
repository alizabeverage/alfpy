{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, copy, pickle, numpy as np\n",
    "from func import func\n",
    "from alf_vars import *\n",
    "from set_pinit_priors import *\n",
    "from alf_constants import *\n",
    "import emcee, time\n",
    "from multiprocessing import Pool\n",
    "import dynesty\n",
    "from dynesty import NestedSampler, DynamicNestedSampler\n",
    "from priors import TopHat\n",
    "from read_data import *\n",
    "from linterp import *\n",
    "from str2arr import *\n",
    "from getvelz import getvelz\n",
    "#import h5py\n",
    "from contextlib import closing\n",
    "\n",
    "\n",
    "# -------------------------------------------------------- #\n",
    "global use_keys\n",
    "use_keys = ['velz', 'sigma', 'logage', 'zh', 'feh', \n",
    "            'ah', 'ch', 'nh', 'nah', 'mgh', 'cah', 'tih', \n",
    "            'imf1', 'imf2', 'imf3']\n",
    "        \n",
    "        \n",
    "# -------------------------------------------------------- #       \n",
    "def log_prob(posarr):\n",
    "    ln_prior = lnprior(posarr, usekeys = use_keys, \n",
    "                       prhiarr=global_prhiarr, prloarr=global_prloarr, \n",
    "                       nested = False)\n",
    "    if not np.isfinite(ln_prior):\n",
    "        return -np.inf\n",
    "    \n",
    "    return ln_prior - 0.5*func(global_alfvar, posarr, \n",
    "                             prhiarr=global_prhiarr, \n",
    "                             prloarr=global_prloarr, \n",
    "                             usekeys=use_keys)\n",
    "\n",
    "# -------------------------------------------------------- #\n",
    "def log_prob_nested(posarr):\n",
    "    ln_prior = lnprior(posarr, usekeys = use_keys, \n",
    "                       prhiarr=global_prhiarr, prloarr=global_prloarr, \n",
    "                       nested = True)\n",
    "    if not np.isfinite(ln_prior):\n",
    "        return -np.infty\n",
    "    \n",
    "    return ln_prior - 0.5*func(global_alfvar, posarr, \n",
    "                     prhiarr=global_prhiarr, \n",
    "                     prloarr=global_prloarr, \n",
    "                     usekeys=use_keys)\n",
    "    \n",
    "# -------------------------------------------------------- #  \n",
    "def prior_transform(unit_coords):    \n",
    "    theta = np.empty((len(unit_coords)))\n",
    "    key_arr = np.array(['velz', 'sigma', 'logage', 'zh', 'feh', \n",
    "                        'ah', 'ch', 'nh','nah','mgh','sih','kh','cah','tih',\n",
    "                        'vh','crh','mnh','coh','nih','cuh','srh','bah','euh',\n",
    "                        'teff','imf1','imf2','logfy','sigma2','velz2',\n",
    "                            'logm7g','hotteff','loghot','fy_logage',\n",
    "                            'logemline_h','logemline_oii','logemline_oiii',\n",
    "                            'logemline_sii','logemline_ni','logemline_nii',\n",
    "                            'logtrans','jitter','logsky', 'imf3','imf4','h3','h4'])\n",
    "    \n",
    "    for i, ikey in enumerate(use_keys):\n",
    "        ind = np.where(key_arr==ikey)\n",
    "        a = TopHat(global_prloarr[ind].item(), global_prhiarr[ind].item())\n",
    "        theta[i] = a.unit_transform(unit_coords[i])\n",
    "        \n",
    "    return theta   \n",
    "\n",
    "# -------------------------------------------------------- # \n",
    "def lnprior(in_arr, nested=False):\n",
    "    in_pos_arr = fill_param(in_arr, usekeys = use_keys)                \n",
    "    lnp = np.nansum([global_all_prior[i].lnp(in_pos_arr[i]) for i in range(len(in_pos_arr))])\n",
    "    if nested and np.isfinite(lnp):\n",
    "        return 0.0\n",
    "    return lnp\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alfvar = None\n",
    "filename = 'ldss3_dr246_n4055_Re4_wave6e'\n",
    "tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ************************************\n",
      " **********Spectral Fitter***********\n",
      " ************************************\n",
      "   ssp_type  = vcj\n",
      "   fit_type  = 0\n",
      "   imf_type  = 1\n",
      " fit_hermite = 0\n",
      "fit_two_ages = 1\n",
      "  obs_frame  = 1\n",
      "      mwimf  = 0\n",
      "  age-dep Rf = 1\n",
      "    Z-dep Rf = 1\n",
      "  Nwalkers   =  128\n",
      "  Nburn      =  100\n",
      "  Nchain     =  1000\n",
      "  filename   =  ldss3_dr246_n4055_Re4_wave6e   \n",
      " ************************************\n"
     ]
    }
   ],
   "source": [
    "    if alfvar is None:\n",
    "        alfvar = pickle.load(open('../../alfvar_sspgrid_irldss3_imftype3.p', \"rb\" )) \n",
    "        \n",
    "    nmcmc = 1000    # -- number of chain steps to print to file\n",
    "    # -- inverse sampling of the walkers for printing\n",
    "    # -- NB: setting this to >1 currently results in errors in the *sum outputs\n",
    "    nsample = 1\n",
    "    nburn = 100    # -- length of chain burn-in\n",
    "    nwalkers = 128    # -- number of walkers\n",
    "    print_mcmc = 1; print_mcmc_spec = 0    # -- save the chain outputs to file and the model spectra\n",
    "\n",
    "    dopowell = 0  # -- start w/ powell minimization?\n",
    "    ftol = 0.1    # -- Powell iteration tolerance\n",
    "    # -- if set, will print to screen timing of likelihood calls\n",
    "    test_time = 0\n",
    "    # -- number of Monte Carlo realizations of the noise for index errors\n",
    "    nmcindx = 1000\n",
    "\n",
    "    # -- check\n",
    "    totacc = 0; iter_ = 30\n",
    "    minchi2 = huge_number\n",
    "    bret = huge_number\n",
    "    \n",
    "    nl = alfvar.nl\n",
    "    npar = alfvar.npar\n",
    "    nfil = alfvar.nfil\n",
    "\n",
    "    mspec, mspecmw, lam = np.zeros((3, nl))\n",
    "    m2l, m2lmw = np.zeros((2, nfil))\n",
    "    oposarr, bposarr = np.zeros((2, npar))\n",
    "    mpiposarr = np.zeros((npar,nwalkers))\n",
    "    runtot = np.zeros((3,npar+2*nfil))\n",
    "    cl2p5,cl16,cl50,cl84,cl97p5 = np.zeros((5, npar+2*nfil))\n",
    "    #mcmcpar = np.zeros((npar+2*nfil, nwalkers*nmcmc/nsample))\n",
    "\n",
    "    #---------------------------------------------------------------!\n",
    "    #---------------------------Setup-------------------------------!\n",
    "    #---------------------------------------------------------------!\n",
    "    # ---- flag specifying if fitting indices or spectra\n",
    "    alfvar.fit_indices = 0  #flag specifying if fitting indices or spectra\n",
    "\n",
    "    # ---- flag determining the level of complexity\n",
    "    # ---- 0=full, 1=simple, 2=super-simple.  See sfvars for details\n",
    "    alfvar.fit_type = 0\n",
    "\n",
    "    # ---- fit h3 and h4 parameters\n",
    "    alfvar.fit_hermite = 0\n",
    "\n",
    "    # ---- type of IMF to fit\n",
    "    # ---- 0=1PL, 1=2PL, 2=1PL+cutoff, 3=2PL+cutoff, 4=non-parametric IMF\n",
    "    alfvar.imf_type = 1\n",
    "\n",
    "    # ---- are the data in the original observed frame?\n",
    "    alfvar.observed_frame = 1\n",
    "\n",
    "    alfvar.mwimf = 0  #force a MW (Kroupa) IMF\n",
    "\n",
    "    # ---- fit two-age SFH or not?  (only considered if fit_type=0)\n",
    "    alfvar.fit_two_ages = 1\n",
    "\n",
    "    # ---- IMF slope within the non-parametric IMF bins\n",
    "    # ---- 0 = flat, 1 = Kroupa, 2 = Salpeter\n",
    "    alfvar.nonpimf_alpha = 2\n",
    "\n",
    "    # ---- turn on/off the use of an external tabulated M/L prior\n",
    "    alfvar.extmlpr = 0\n",
    "\n",
    "    # ---- change the prior limits to kill off these parameters\n",
    "    pos, prlo, prhi = set_pinit_priors(alfvar)\n",
    "    prhi.logm7g = -5.0\n",
    "    prhi.teff   =  2.0\n",
    "    prlo.teff   = -2.0\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------!\n",
    "    # --------------Do not change things below this line-------------!\n",
    "    # ---------------unless you know what you are doing--------------!\n",
    "    # ---------------------------------------------------------------!\n",
    "\n",
    "    # ---- regularize non-parametric IMF (always do this)\n",
    "    alfvar.nonpimf_regularize = 1\n",
    "\n",
    "    # ---- dont fit transmission function in cases where the input\n",
    "    # ---- spectrum has already been de-redshifted to ~0.0\n",
    "    if (alfvar.observed_frame == 0.) or (alfvar.fit_indices == 1):\n",
    "        alfvar.fit_trans = 0\n",
    "        prhi.logtrans = -5.0\n",
    "        prhi.logsky   = -5.0\n",
    "    else:\n",
    "        alfvar.fit_trans = 1\n",
    "        \"\"\"\n",
    "        # ---- extra smoothing to the transmission spectrum.\n",
    "        # ---- if the input data has been smoothed by a gaussian\n",
    "        # ---- in velocity space, set the parameter below to that extra smoothing        \n",
    "        \"\"\"\n",
    "        alfvar.smooth_trans = 0.0\n",
    "\n",
    "    if (alfvar.ssp_type == 'cvd'):\n",
    "        # ---- always limit the [Z/H] range for CvD since\n",
    "        # ---- these models are actually only at Zsol\n",
    "        prhi.zh =  0.01\n",
    "        prlo.zh = -0.01\n",
    "        if (alfvar.imf_type > 1):\n",
    "            print('ALF ERROR, ssp_type=cvd but imf>1')\n",
    "\n",
    "    if alfvar.fit_type in [1,2]:\n",
    "        alfvar.mwimf=1\n",
    "\n",
    "    #---------------------------------------------------------------!\n",
    "\n",
    "    if filename is None:\n",
    "        print('ALF ERROR: You need to specify an input file')\n",
    "        teminput = input(\"Name of the input file: \")\n",
    "        if len(teminput.split(' '))==1:\n",
    "            filename = teminput\n",
    "        elif len(teminput.split(' '))>1:\n",
    "            filename = teminput[0]\n",
    "            tag = teminput[1]\n",
    "\n",
    "\n",
    "    # ---- write some important variables to screen\n",
    "    print(\" ************************************\")\n",
    "    if alfvar.fit_indices == 1:\n",
    "        print(\" ***********Index Fitter*************\")\n",
    "    else:\n",
    "        print(\" **********Spectral Fitter***********\")\n",
    "    print(\" ************************************\")\n",
    "    print(\"   ssp_type  =\", alfvar.ssp_type)\n",
    "    print(\"   fit_type  =\", alfvar.fit_type)\n",
    "    print(\"   imf_type  =\", alfvar.imf_type)\n",
    "    print(\" fit_hermite =\", alfvar.fit_hermite)\n",
    "    print(\"fit_two_ages =\", alfvar.fit_two_ages)\n",
    "    if alfvar.imf_type == 4:\n",
    "        print(\"   nonpimf   =\", alfvar.nonpimf_alpha)\n",
    "    print(\"  obs_frame  =\",  alfvar.observed_frame)\n",
    "    print(\"      mwimf  =\",  alfvar.mwimf)\n",
    "    print(\"  age-dep Rf =\",  alfvar.use_age_dep_resp_fcns)\n",
    "    print(\"    Z-dep Rf =\",  alfvar.use_z_dep_resp_fcns)\n",
    "    print(\"  Nwalkers   = \",  nwalkers)\n",
    "    print(\"  Nburn      = \",  nburn)\n",
    "    print(\"  Nchain     = \",  nmcmc)\n",
    "    #print(\"  Ncores     = \",  ntasks)\n",
    "    print(\"  filename   = \",  filename, ' ', tag)\n",
    "    print(\" ************************************\")\n",
    "    #print('\\n\\nStart Time ',datetime.now())\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------!\n",
    "    # ---- read in the data and wavelength boundaries\n",
    "    alfvar.filename = filename\n",
    "    alfvar.tag = tag    \n",
    "\n",
    "\n",
    "    if alfvar.fit_indices == 0:\n",
    "        alfvar = read_data(alfvar)\n",
    "        # ---- read in the SSPs and bandpass filters\n",
    "        #alfvar = setup(alfvar)\n",
    "        lam = np.copy(alfvar.sspgrid.lam)\n",
    "\n",
    "        # ---- interpolate the sky emission model onto the observed wavelength grid\n",
    "        if alfvar.observed_frame == 1:\n",
    "            alfvar.data.sky = linterp(alfvar.lsky, alfvar.fsky, alfvar.data.lam)\n",
    "            alfvar.data.sky[alfvar.data.sky<0] = 0.                               \n",
    "        else:\n",
    "            alfvar.data.sky[:] = tiny_number\n",
    "        alfvar.data.sky[:] = tiny_number\n",
    "\n",
    "        # ---- we only compute things up to 500A beyond the input fit region\n",
    "        alfvar.nl_fit = min(max(locate(lam, alfvar.l2[-1]+500.0),0),alfvar.nl-1)\n",
    "\n",
    "        #define the log wavelength grid used in velbroad.f90\n",
    "        alfvar.dlstep = (np.log(alfvar.sspgrid.lam[alfvar.nl_fit])-\n",
    "                         np.log(alfvar.sspgrid.lam[0]))/alfvar.nl_fit\n",
    "        \n",
    "        for i in range(alfvar.nl_fit):\n",
    "            alfvar.lnlam[i] = i*alfvar.dlstep + np.log(alfvar.sspgrid.lam[0])\n",
    "\n",
    "        # ---- masked regions have wgt=0.0.  We'll use wgt as a pseudo-error\n",
    "        # ---- array in contnormspec, so turn these into large numbers\n",
    "        alfvar.data.wgt = 1./(alfvar.data.wgt+tiny_number)\n",
    "        alfvar.data.wgt[alfvar.data.wgt>huge_number] = huge_number\n",
    "        # ---- fold the masked regions into the errors\n",
    "        alfvar.data.err = alfvar.data.err * alfvar.data.wgt\n",
    "        alfvar.data.err[alfvar.data.err>huge_number] = huge_number\n",
    "\n",
    "\n",
    "    # ---- set initial params, step sizes, and prior ranges\n",
    "    opos,prlo,prhi = set_pinit_priors(alfvar)\n",
    "    # ---- convert the structures into their equivalent arrays\n",
    "    prloarr = str2arr(switch=1, instr = prlo)\n",
    "    prhiarr = str2arr(switch=1, instr = prhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting  6  wavelength intervals\n",
      "wavelength bourdaries:  [4000. 4700. 5700. 6750. 8000. 9630.] [ 4700.  5700.  6750.  8000.  8920. 10100.]\n",
      " Fitting cz...\n",
      "    cz=  7382.0  (z= 0.07382 )\n",
      "\n",
      "We are going to fit  ['velz', 'sigma', 'logage', 'zh', 'feh', 'ah', 'ch', 'nh', 'nah', 'mgh', 'cah', 'tih', 'imf1', 'imf2', 'imf3'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "    if (alfvar.fit_indices == 0):\n",
    "        print(\"  Fitting \",alfvar.nlint,\" wavelength intervals\")\n",
    "        nlint = alfvar.nlint\n",
    "        l1, l2 = alfvar.l1, alfvar.l2\n",
    "        print('wavelength bourdaries: ', l1, l2)\n",
    "        if l2[-1]>np.nanmax(lam) or l1[0]<np.nanmin(lam):\n",
    "            print('ERROR: wavelength boundaries exceed model wavelength grid')\n",
    "            print(l2[nlint-1],lam[nl-1],l1[0],lam[0])\n",
    "\n",
    "        # ---- make an initial estimate of the redshift\n",
    "        print(' Fitting cz...')\n",
    "        velz = getvelz(alfvar)\n",
    "        if velz < prlo.velz or velz > prhi.velz:\n",
    "            print('cz', velz,' out of prior bounds, setting to 0.0')\n",
    "            velz = 0.0\n",
    "        opos.velz = velz\n",
    "        print(\"    cz= \",opos.velz,\" (z=\",opos.velz/1e5,\")\")\n",
    "\n",
    "        oposarr = str2arr(switch=1, instr=opos)\n",
    "        \n",
    "        global global_alfvar, global_prloarr, global_prhiarr\n",
    "        global_alfvar = copy.deepcopy(alfvar)\n",
    "        global_prloarr = copy.deepcopy(prloarr)\n",
    "        global_prhiarr = copy.deepcopy(prhiarr)\n",
    "        global global_all_prior\n",
    "        global_all_prior = [TopHat(prloarr[i], prhiarr[i]) for i in range(len(key_list))]\n",
    "        \n",
    "\n",
    "        print('\\nWe are going to fit ', use_keys, '\\n')\n",
    "        npar = len(use_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.38200000e+03,  1.93198562e+02,  6.46358170e-01, -2.23954182e-01,\n",
       "        -1.50514609e-01,  3.56989539e-02,  5.42865217e-03, -1.46121980e-01,\n",
       "         8.66092233e-02, -7.76402168e-02,  6.83258751e-02, -7.58764014e-04,\n",
       "        -1.49337082e-02, -9.31607125e-02,  1.69801665e-01,  8.90091211e-02,\n",
       "         1.41036003e-01, -1.81122974e-01,  3.56658158e-02,  2.44976266e-02,\n",
       "         2.26083914e-03,  3.43121678e-02,  9.16410749e-02, -5.19001018e+00,\n",
       "         1.34498749e+00,  2.21708700e+00, -2.51859897e+00,  1.84484392e+02,\n",
       "        -4.68819419e+00, -3.75618474e+00,  1.63676129e+01, -3.87183195e+00,\n",
       "         2.89781169e-02, -2.43154792e+00, -2.21100578e+00, -2.23028825e+00,\n",
       "        -3.13916581e+00, -2.14868340e+00, -3.64358049e+00, -1.94444238e+00,\n",
       "         1.14865857e+00, -5.11666364e+00,  1.86856182e-01,  1.53491419e-01,\n",
       "         4.16029734e-03,  1.68642962e-03]),\n",
       " array([ 7.38200000e+03,  1.93198562e+02,  6.46358170e-01, -2.23954182e-01,\n",
       "        -1.50514609e-01,  3.56989539e-02,  5.42865217e-03, -1.46121980e-01,\n",
       "         8.66092233e-02, -7.76402168e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.49337082e-02, -9.31607125e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.34498749e+00,  2.21708700e+00, -4.00000000e+00,  1.10000000e+01,\n",
       "         0.00000000e+00, -4.00000000e+00,  2.00000000e+01, -4.00000000e+00,\n",
       "         3.00000000e-01, -4.00000000e+00, -4.00000000e+00, -4.00000000e+00,\n",
       "        -4.00000000e+00, -4.00000000e+00, -4.00000000e+00, -4.00000000e+00,\n",
       "         1.00000000e+00, -4.00000000e+00,  1.86856182e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_pos_arr = fill_param(oposarr, usekeys = use_keys) \n",
    "oposarr, in_pos_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.839580911706463, -6.897704943128636, 0.40196108294328076, -0.7419373447293773, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, -0.26236426446749106, -0.26236426446749106, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, 0.2231435513142097, -0.09531017980432493, 0.0, -4.605170185988092, -1.0986122886681098, -1.0986122886681098, -1.7749523509116738, -6.897704943128636, -10.839580911706463, -1.6094379124341003, -3.091042453358316, -1.9459101490553132, 0.2508343644652965, -1.9459101490553132, -1.9459101490553132, -1.9459101490553132, -1.9459101490553132, -1.9459101490553132, -1.9459101490553132, -1.9459101490553132, -2.2925347571405443, -2.3978952727983707, 1.1394342831883648, -2.0794415416798357, 0.2231435513142097, 0.2231435513142097]\n"
     ]
    }
   ],
   "source": [
    "l = [global_all_prior[i].lnp(in_pos_arr[i]) for i in range(len(in_pos_arr))]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = ['velz', 'sigma', 'logage', 'zh', 'feh', \n",
    "            'ah', 'ch', 'nh','nah','mgh','sih','kh','cah','tih',\n",
    "            'vh','crh','mnh','coh','nih','cuh','srh','bah','euh',\n",
    "                'teff','imf1','imf2','logfy','sigma2','velz2',\n",
    "                'logm7g','hotteff','loghot','fy_logage',\n",
    "                'logemline_h','logemline_oii','logemline_oiii',\n",
    "                'logemline_sii','logemline_ni','logemline_nii',\n",
    "                'logtrans','jitter','logsky', 'imf3','imf4','h3','h4']\n",
    "\n",
    "key_arr = np.array(key_list)\n",
    "\n",
    "default_arr = np.array([0.0, 11.0, 1.0, 0.0, 0.0,0.0,0.0,0.0, 0.0, 0.0,  \n",
    "                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "                        0.0, 0.0, 0.0, 0.0, 0.0, 1.3, 2.3, -4.0, \n",
    "                        11.0, 0.0, -4.0, 20.0, -4.0, 0.3, \n",
    "                        -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, \n",
    "                        -4.0, 1.0, -4.0, 0.10, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
